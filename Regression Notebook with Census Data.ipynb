{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Notebook with Census Data\n",
    "\n",
    "The purpose of this notebook is to find explanatory variables that influence the volume of groundwater testing in California. More information on data and context can be found in the  (1) Background and (2) Data Notion pages to better understand the data being used.\n",
    "\n",
    "## Specialty Imports\n",
    "* Zipcode and SearchEngine will be utilized for a reverse geocoding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/app/venv/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "#Set Up\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# GIS/Location Related\"\n",
    "from uszipcode import Zipcode\n",
    "from uszipcode import SearchEngine\n",
    "search = SearchEngine(simple_zipcode=True)\n",
    "\n",
    "# Regression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse geocoder function\n",
    "Credits: https://stackoverflow.com/questions/60324730/reverse-geo-coding-without-google-api-for-zip-codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_to_zip(lat,lng):\n",
    "    \"\"\" \n",
    "    Reverse geocoder that takes a lat and longitude value and finds the zipcode\n",
    "    \"\"\"\n",
    "    zip_code = []\n",
    "    for x,y in zip(lat,lng):\n",
    "        result = search.by_coordinates(lat=x, lng=y, radius=14, returns=5)\n",
    "        zip_code.append(result[0].zipcode)\n",
    "    return zip_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "We will be using the cleaned data from Ro that has various ACS forms/Census forms compiled by zipcode. Learn more at the Data tab of the Notion page!\n",
    "https://github.com/Ro-Data/Ro-Census-Summaries-By-Zipcode/blob/master/\n",
    " \n",
    "* _income_ measures wealth and taxes by zipcode\n",
    "* _demo_ provides demographics by zipcode\n",
    "* _econ_ measures employment by zipcode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv('assorted_data/income_by_zip.csv')\n",
    "income = income[['Zipcode','TotalWages']].rename({'Zipcode': 'Zip Code'}, axis = 1)\n",
    "\n",
    "demo = pd.read_csv('census_data/demo.txt', sep = '\\t').dropna()#fillna(method='ffill')\n",
    "demo['Zip Code'] = demo['ZCTA5']\n",
    "\n",
    "econ = pd.read_csv('census_data/econ.txt', sep = '\\t').dropna()#fillna(method='ffill')\n",
    "econ['Zip Code'] = demo['ZCTA5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The following hashed out code will reverse-geocode the GAMA data but\n",
    "# due to the long run time.\n",
    "\n",
    "# gama['Zip Code'] = coord_to_zip(gama['latitude'], gama['longitude'])\n",
    "# gama.to_csv(\"gama_2019_geocoded.csv\")\n",
    "\n",
    "\n",
    "# Loads pre-geocoded GAMA data\n",
    "gama = pd.read_csv('gama_data/gama_2019_geocoded.csv').dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Wrangling\n",
    "\n",
    "### Aggregating the number of tests and then counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91950</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92058</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92061</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92071</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92086</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zip Code  results\n",
       "0     91950       82\n",
       "1     92058       82\n",
       "2     92061       76\n",
       "3     92071       74\n",
       "4     92086      157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gama_test_counts = pd.DataFrame(gama.groupby(['Zip Code'])['results'].agg('count')).reset_index().astype(int)\n",
    "gama_test_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the dataframes, then using more readable labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 380)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gama_demo = pd.merge(left = gama_test_counts, right = demo, on = 'Zip Code')\n",
    "g_d_econ  = pd.merge(left = gama_demo, right = econ, on = 'Zip Code')\n",
    "\n",
    "final = g_d_econ.rename({'results': \"Number of Tests\",}, axis = 1)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "\n",
    "It is not ideal that we could only find information for 18 zip codes. A naive single-variable OLS will likely suffer from large standard errors. Luckily, the aim of this project is to _explore_ possible features rather than conclusively determine features. In the future, I would want to spend more time cleaning and exploring the data. Ideas I have currently are:\n",
    "\n",
    "1. Running PCA on the 379 features and then cross validating to measure my error. I haven't investigated all the features and it might be that the census data is inherently low rank. For example, there may be many linear combinations of income measures. \n",
    "2. Stepwise Regression, Backward Selection, or Forward Selection for feature selection\n",
    "\n",
    "However let's see if the data we have, again which is by zipcode, describes a region. For example, what if all the zipcodes were in the South Bay? From that perspective, we actually have as rich of a granularity we could ask for!\n",
    "\n",
    "\n",
    "Click Here to View in Your Browser\n",
    " ==> https://www.easymapmaker.com/map/0191e9e8c3e6855fe1e390003db8c360\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![final_map](./images/final_map.png \"Rough Plot of Final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! While a more rigorous data cleaning process could probability give us more results for more regions in California. This \"EDA\" of sorts provides the following insights\n",
    "\n",
    "* We can filter the 'final' dataframe for Fresno-tangent locations such that we could use our results to explain the Fresno region.\n",
    "* Future cleaning could allow us to create models and associative claims for regions within California\n",
    "\n",
    "\n",
    "# A Simple Model for Fresno, California\n",
    "\n",
    "Out of curiosity let's run a simple single-variable OLS and feature slection process for the sake of exploration. Zipcodes that are in Fresno and the 'final' dataframe begin with '93xxx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresno = final[final['Zip Code'] > 93000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = fresno.corr()\n",
    "corr_target = abs(corr[\"Number of Tests\"])\n",
    "\n",
    "#Selecting highly correlated features\n",
    "relevant_features = corr_target[corr_target>0.5].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Number of Tests</td> <th>  R-squared:         </th> <td>   0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 21 May 2020</td> <th>  Prob (F-statistic):</th>  <td>0.0824</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:23:08</td>     <th>  Log-Likelihood:    </th> <td> -61.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   126.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    10</td>      <th>  BIC:               </th> <td>   127.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                                <td></td>                                                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                                                                         <td>   81.7300</td> <td>   15.093</td> <td>    5.415</td> <td> 0.000</td> <td>   48.101</td> <td>  115.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hispanic_or_latino_and_race_detailed-population-not_hispanic_or_latino_other_total_population</th> <td>    0.4366</td> <td>    0.226</td> <td>    1.930</td> <td> 0.082</td> <td>   -0.067</td> <td>    0.941</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.353</td> <th>  Durbin-Watson:     </th> <td>   1.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.187</td> <th>  Jarque-Bera (JB):  </th> <td>   1.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.860</td> <th>  Prob(JB):          </th> <td>   0.474</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.165</td> <th>  Cond. No.          </th> <td>    79.7</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        Number of Tests   R-squared:                       0.271\n",
       "Model:                            OLS   Adj. R-squared:                  0.199\n",
       "Method:                 Least Squares   F-statistic:                     3.726\n",
       "Date:                Thu, 21 May 2020   Prob (F-statistic):             0.0824\n",
       "Time:                        16:23:08   Log-Likelihood:                -61.280\n",
       "No. Observations:                  12   AIC:                             126.6\n",
       "Df Residuals:                      10   BIC:                             127.5\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================================================================================\n",
       "                                                                                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
       "const                                                                                            81.7300     15.093      5.415      0.000      48.101     115.359\n",
       "hispanic_or_latino_and_race_detailed-population-not_hispanic_or_latino_other_total_population     0.4366      0.226      1.930      0.082      -0.067       0.941\n",
       "==============================================================================\n",
       "Omnibus:                        3.353   Durbin-Watson:                   1.763\n",
       "Prob(Omnibus):                  0.187   Jarque-Bera (JB):                1.492\n",
       "Skew:                           0.860   Prob(JB):                        0.474\n",
       "Kurtosis:                       3.165   Cond. No.                         79.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = fresno[[\"Number of Tests\"]]\n",
    "\n",
    "\n",
    "X_train = fresno[['hispanic_or_latino_and_race_detailed-population-not_hispanic_or_latino_other_total_population']]\n",
    "\n",
    "X_with_const = sm.add_constant(X_train)\n",
    "\n",
    "linear_model = sm.OLS(Y, X_with_const).fit()\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* PCA and Small Sample Sizes https://stats.stackexchange.com/questions/116132/regression-with-very-small-sample-size\n",
    "\n",
    "* Feature Selection https://towardsdatascience.com/feature-selection-techniques-in-regression-model-26878fe0e24e\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
